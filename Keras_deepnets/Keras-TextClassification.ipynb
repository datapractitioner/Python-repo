{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "import string\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Using 60000 files for training.\n",
      "Found 75000 files belonging to 3 classes.\n",
      "Using 15000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create training and validation data\n",
    "batch_size = 64\n",
    "main_path = 'D:/keras_datasets/aclImdb'\n",
    "train_path = os.path.join(main_path, 'train')\n",
    "test_path = os.path.join(main_path, 'test')\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_path,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = .2,\n",
    "    subset = 'training',\n",
    "    seed = 1337   # always set a seed for reproducibility\n",
    ")\n",
    "\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_path,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation',\n",
    "    seed = 1337 # always set a seed for reproducibility\n",
    ")\n",
    "\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    test_path, batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, abel_batch in raw_train_ds.take(1):\n",
    "    # In order to test the data generator we can sample 64 of them randomly\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data) # built-in tf function to operate on tesors\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'spoilers we sit through ten minutes of awful clich\\xc3\\xa9d dialog at the beginning from two completely unoriginal characters with bad twangs ripped off from kalifornia and natural born killers  there isnt an original thing about these two and youre going either theyre about to kill everyone in the diner or already have and lo and behold guess what happens  i cant stand all the tarantino wannabes out there and this guy is one of the worst i got maybe 2530 minutes into the thing when i just couldnt take it and stopped watching miners really bad acting was unbearable  i couldnt take it that and the terrible script after reading some of these comments i see there was a big twist  well guess what no one cares when you create completely uninteresting unoriginal and unlikeable character like these two clich\\xc3\\xa9s no one cares what big twist may have happened i hope this is the end of these types of movies'>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# How the custom preprocessing function would do on the sampled data\n",
    "custom_standardization(text_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}